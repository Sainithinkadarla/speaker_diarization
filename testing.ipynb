{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4f2e62",
   "metadata": {},
   "source": [
    "### Speaker diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8887a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     10\u001b[39m headers = {\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mauthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.getenv(\u001b[33m\"\u001b[39m\u001b[33mAAI_KEY\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m }\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTranscription/Case 07.m4a\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m   response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v2/upload\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m upload_url = response.json()[\u001b[33m\"\u001b[39m\u001b[33mupload_url\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     21\u001b[39m data = {\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maudio_url\u001b[39m\u001b[33m\"\u001b[39m: upload_url, \u001b[38;5;66;03m# You can also use a URL to an audio or video file on the web\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mspeaker_labels\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     24\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\urllib3\\connection.py:508\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    506\u001b[39m             \u001b[38;5;28mself\u001b[39m.send(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%x\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33mb\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mlen\u001b[39m(chunk), chunk))\n\u001b[32m    507\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[38;5;66;03m# Regardless of whether we have a body or not, if we're in\u001b[39;00m\n\u001b[32m    511\u001b[39m \u001b[38;5;66;03m# chunked mode we want to send an explicit empty chunk.\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunked:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1055\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1053\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.send\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, data)\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections.abc.Iterable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1210\u001b[39m, in \u001b[36mSSLSocket.sendall\u001b[39m\u001b[34m(self, data, flags)\u001b[39m\n\u001b[32m   1208\u001b[39m         amount = \u001b[38;5;28mlen\u001b[39m(byte_view)\n\u001b[32m   1209\u001b[39m         \u001b[38;5;28;01mwhile\u001b[39;00m count < amount:\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m             v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1211\u001b[39m             count += v\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1179\u001b[39m, in \u001b[36mSSLSocket.send\u001b[39m\u001b[34m(self, data, flags)\u001b[39m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1176\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1177\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1178\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().send(data, flags)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from csv import writer\n",
    "\n",
    "base_url = \"https://api.assemblyai.com\"\n",
    "\n",
    "headers = {\n",
    "    \"authorization\": f\"{os.getenv(\"AAI_KEY\")}\"\n",
    "}\n",
    "\n",
    "with open(\"Transcription/Case 07.m4a\", \"rb\") as f:\n",
    "  response = requests.post(base_url + \"/v2/upload\",\n",
    "                          headers=headers,\n",
    "                          data=f)\n",
    "\n",
    "upload_url = response.json()[\"upload_url\"]\n",
    "\n",
    "data = {\n",
    "    \"audio_url\": upload_url, # You can also use a URL to an audio or video file on the web\n",
    "    \"speaker_labels\": True\n",
    "}\n",
    "\n",
    "url = base_url + \"/v2/transcript\"\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "transcript_id = response.json()['id']\n",
    "polling_endpoint = base_url + \"/v2/transcript/\" + transcript_id\n",
    "\n",
    "while True:\n",
    "  transcription_result = requests.get(polling_endpoint, headers=headers).json()\n",
    "\n",
    "  if transcription_result['status'] == 'completed':\n",
    "    print(f\"Transcript ID:\", transcript_id)\n",
    "    break\n",
    "\n",
    "  elif transcription_result['status'] == 'error':\n",
    "    raise RuntimeError(f\"Transcription failed: {transcription_result['error']}\")\n",
    "\n",
    "  else:\n",
    "    time.sleep(3)\n",
    "transcription = writer(open(\"transcribe.csv\", \"w\", newline = \"\", encoding=\"utf-8\"))\n",
    "transcription.writerow([\"speaker\", \"start\", \"end\", \"word\"])\n",
    "for utterance in transcription_result['utterances']:\n",
    "  print(f\"Speaker {utterance['speaker']}: {utterance['text']} from {utterance['start']} to {utterance[\"end\"]}\")\n",
    "  transcription.writerow([utterance[\"speaker\"], utterance[\"start\"], utterance[\"end\"], utterance[\"text\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e96bfc",
   "metadata": {},
   "source": [
    "### Only transcibing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed569e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cdn.assemblyai.com/upload/31d5df94-403d-4d80-a185-b76e8950cf2b\n",
      "Transcript ID: 19921fec-e27c-4e0d-8bce-9378b7fd9574\n",
      "{'id': '19921fec-e27c-4e0d-8bce-9378b7fd9574', 'language_model': 'assemblyai_default', 'acoustic_model': 'assemblyai_default', 'language_code': 'en_us', 'status': 'completed', 'audio_url': 'https://cdn.assemblyai.com/upload/31d5df94-403d-4d80-a185-b76e8950cf2b', 'text': 'What do you want? B ball. B ball. Ball. Ball, please. Great job.', 'words': [{'text': 'What', 'start': 1120, 'end': 1280, 'confidence': 0.9995117, 'speaker': None}, {'text': 'do', 'start': 1280, 'end': 1480, 'confidence': 1.0, 'speaker': None}, {'text': 'you', 'start': 1480, 'end': 1640, 'confidence': 1.0, 'speaker': None}, {'text': 'want?', 'start': 1640, 'end': 1920, 'confidence': 0.99902344, 'speaker': None}, {'text': 'B', 'start': 2320, 'end': 2720, 'confidence': 0.55810547, 'speaker': None}, {'text': 'ball.', 'start': 4480, 'end': 4880, 'confidence': 0.75146484, 'speaker': None}, {'text': 'B', 'start': 5680, 'end': 6080, 'confidence': 0.48510742, 'speaker': None}, {'text': 'ball.', 'start': 8560, 'end': 8960, 'confidence': 0.89990234, 'speaker': None}, {'text': 'Ball.', 'start': 9920, 'end': 10320, 'confidence': 0.9970703, 'speaker': None}, {'text': 'Ball,', 'start': 10640, 'end': 11040, 'confidence': 0.95947266, 'speaker': None}, {'text': 'please.', 'start': 11040, 'end': 11440, 'confidence': 0.9995117, 'speaker': None}, {'text': 'Great', 'start': 11440, 'end': 11840, 'confidence': 0.99902344, 'speaker': None}, {'text': 'job.', 'start': 11840, 'end': 12240, 'confidence': 0.9995117, 'speaker': None}], 'utterances': None, 'confidence': 0.8959773, 'audio_duration': 13, 'punctuate': True, 'format_text': True, 'dual_channel': None, 'webhook_url': None, 'webhook_status_code': None, 'webhook_auth': False, 'webhook_auth_header_name': None, 'speed_boost': False, 'auto_highlights_result': None, 'auto_highlights': False, 'audio_start_from': None, 'audio_end_at': None, 'word_boost': [], 'boost_param': None, 'prompt': None, 'keyterms_prompt': [], 'filter_profanity': False, 'redact_pii': False, 'redact_pii_audio': False, 'redact_pii_audio_quality': None, 'redact_pii_audio_options': None, 'redact_pii_policies': None, 'redact_pii_sub': None, 'speaker_labels': False, 'speaker_options': None, 'content_safety': False, 'iab_categories': False, 'content_safety_labels': {'status': 'unavailable', 'results': [], 'summary': {}}, 'iab_categories_result': {'status': 'unavailable', 'results': [], 'summary': {}}, 'language_detection': False, 'language_confidence_threshold': None, 'language_confidence': None, 'custom_spelling': None, 'throttled': False, 'auto_chapters': False, 'summarization': False, 'summary_type': None, 'summary_model': None, 'custom_topics': False, 'topics': [], 'speech_threshold': None, 'speech_model': 'universal', 'chapters': None, 'disfluencies': False, 'entity_detection': False, 'sentiment_analysis': False, 'sentiment_analysis_results': None, 'entities': None, 'speakers_expected': None, 'summary': None, 'custom_topics_results': None, 'is_deleted': None, 'multichannel': None, 'project_id': 635516, 'token_id': 640106}\n",
      "What, from 1120 to 1280\n",
      "do, from 1280 to 1480\n",
      "you, from 1480 to 1640\n",
      "want?, from 1640 to 1920\n",
      "B, from 2320 to 2720\n",
      "ball., from 4480 to 4880\n",
      "B, from 5680 to 6080\n",
      "ball., from 8560 to 8960\n",
      "Ball., from 9920 to 10320\n",
      "Ball,, from 10640 to 11040\n",
      "please., from 11040 to 11440\n",
      "Great, from 11440 to 11840\n",
      "job., from 11840 to 12240\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from csv import writer\n",
    "load_dotenv()\n",
    "\n",
    "base_url = \"https://api.assemblyai.com\"\n",
    "\n",
    "headers = {\n",
    "    \"authorization\": os.getenv('AAI_KEY')\n",
    "}\n",
    "\n",
    "with open(\"Transcription/Case 07.m4a\", \"rb\") as f:\n",
    "  response = requests.post(base_url + \"/v2/upload\",\n",
    "                          headers=headers,\n",
    "                          data=f)\n",
    "\n",
    "upload_url = response.json()[\"upload_url\"]\n",
    "print(upload_url)\n",
    "\n",
    "data = {\n",
    "    \"audio_url\": upload_url, # You can also use a URL to an audio or video file on the web\n",
    "    \"speech_model\": \"universal\"\n",
    "    # \"speech_model\": \"slam-1\"\n",
    "}\n",
    "\n",
    "url = base_url + \"/v2/transcript\"\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "transcript_id = response.json()['id']\n",
    "polling_endpoint = base_url + \"/v2/transcript/\" + transcript_id\n",
    "\n",
    "while True:\n",
    "  transcription_result = requests.get(polling_endpoint, headers=headers).json()\n",
    "\n",
    "  if transcription_result['status'] == 'completed':\n",
    "    print(f\"Transcript ID:\", transcript_id)\n",
    "    break\n",
    "\n",
    "  elif transcription_result['status'] == 'error':\n",
    "    raise RuntimeError(f\"Transcription failed: {transcription_result['error']}\")\n",
    "\n",
    "  else:\n",
    "    time.sleep(3)\n",
    "\n",
    "csv_writer = writer(open(\"transcribe.csv\", \"w\", encoding=\"utf-8\", newline=\"\"))\n",
    "\n",
    "print(transcription_result)\n",
    "csv_writer.writerow([\"word\", \"start\", \"end\"])\n",
    "for result in transcription_result[\"words\"]:\n",
    "    print(f\"{result[\"text\"]}, from {result['start']} to {result[\"end\"]}\")\n",
    "    csv_writer.writerow([result[\"text\"], result[\"start\"], result[\"end\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e3ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'What', 'start': 1120, 'end': 1280, 'confidence': 0.9995117, 'speaker': None}\n",
      "{'text': 'do', 'start': 1280, 'end': 1480, 'confidence': 1.0, 'speaker': None}\n",
      "{'text': 'you', 'start': 1480, 'end': 1640, 'confidence': 1.0, 'speaker': None}\n",
      "{'text': 'want?', 'start': 1640, 'end': 1920, 'confidence': 0.99902344, 'speaker': None}\n",
      "{'text': 'B', 'start': 2320, 'end': 2720, 'confidence': 0.55810547, 'speaker': None}\n",
      "{'text': 'ball.', 'start': 4480, 'end': 4880, 'confidence': 0.75146484, 'speaker': None}\n",
      "{'text': 'B', 'start': 5680, 'end': 6080, 'confidence': 0.48510742, 'speaker': None}\n",
      "{'text': 'ball.', 'start': 8560, 'end': 8960, 'confidence': 0.89990234, 'speaker': None}\n",
      "{'text': 'Ball.', 'start': 9920, 'end': 10320, 'confidence': 0.9970703, 'speaker': None}\n",
      "{'text': 'Ball,', 'start': 10640, 'end': 11040, 'confidence': 0.95947266, 'speaker': None}\n",
      "{'text': 'please.', 'start': 11040, 'end': 11440, 'confidence': 0.9995117, 'speaker': None}\n",
      "{'text': 'Great', 'start': 11440, 'end': 11840, 'confidence': 0.99902344, 'speaker': None}\n",
      "{'text': 'job.', 'start': 11840, 'end': 12240, 'confidence': 0.9995117, 'speaker': None}\n"
     ]
    }
   ],
   "source": [
    "for result in transcription_result[\"words\"]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What, from 1120 to 1280\n",
      "do, from 1280 to 1480\n",
      "you, from 1480 to 1640\n",
      "want?, from 1640 to 1920\n",
      "B, from 2320 to 2720\n",
      "ball., from 4480 to 4880\n",
      "B, from 5680 to 6080\n",
      "ball., from 8560 to 8960\n",
      "Ball., from 9920 to 10320\n",
      "Ball,, from 10640 to 11040\n",
      "please., from 11040 to 11440\n",
      "Great, from 11440 to 11840\n",
      "job., from 11840 to 12240\n"
     ]
    }
   ],
   "source": [
    "for result in transcription_result[\"words\"]:\n",
    "    print(f\"{result[\"text\"]}, from {result['start']} to {result[\"end\"]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d7b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "d:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sainithin\\.cache\\torch\\pyannote\\models--pyannote--segmentation. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\sainithin\\.cache\\torch\\pyannote\\models--pyannote--segmentation\\snapshots\\c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.7.1+cpu. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sainithin\\.cache\\huggingface\\hub\\models--speechbrain--spkrec-ecapa-voxceleb. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "d:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\sainithin\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--spkrec-ecapa-voxceleb\\\\snapshots\\\\0f99f2d0ebe89ac095bcc5903c4dd8f72b367286\\\\hyperparams.yaml' -> 'C:\\\\Users\\\\sainithin\\\\.cache\\\\torch\\\\pyannote\\\\speechbrain\\\\hyperparams.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(HF_KEY)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyannote\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m pipeline = \u001b[43mPipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyannote/speaker-diarization\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m  \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHF_KEY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# run the pipeline on an audio file\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTranscription/Case 07.m4a\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\pyannote\\audio\\core\\pipeline.py:138\u001b[39m, in \u001b[36mPipeline.from_pretrained\u001b[39m\u001b[34m(cls, checkpoint_path, hparams_file, use_auth_token, cache_dir)\u001b[39m\n\u001b[32m    136\u001b[39m params = config[\u001b[33m\"\u001b[39m\u001b[33mpipeline\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    137\u001b[39m params.setdefault(\u001b[33m\"\u001b[39m\u001b[33muse_auth_token\u001b[39m\u001b[33m\"\u001b[39m, use_auth_token)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m pipeline = \u001b[43mKlass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# freeze  parameters\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfreeze\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_diarization.py:166\u001b[39m, in \u001b[36mSpeakerDiarization.__init__\u001b[39m\u001b[34m(self, segmentation, segmentation_step, embedding, embedding_exclude_overlap, clustering, embedding_batch_size, segmentation_batch_size, der_variant, use_auth_token)\u001b[39m\n\u001b[32m    163\u001b[39m     metric = \u001b[33m\"\u001b[39m\u001b[33mnot_applicable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28mself\u001b[39m._embedding = \u001b[43mPretrainedSpeakerEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_auth_token\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28mself\u001b[39m._audio = Audio(sample_rate=\u001b[38;5;28mself\u001b[39m._embedding.sample_rate, mono=\u001b[33m\"\u001b[39m\u001b[33mdownmix\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    170\u001b[39m     metric = \u001b[38;5;28mself\u001b[39m._embedding.metric\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:750\u001b[39m, in \u001b[36mPretrainedSpeakerEmbedding\u001b[39m\u001b[34m(embedding, device, use_auth_token)\u001b[39m\n\u001b[32m    745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyannoteAudioPretrainedSpeakerEmbedding(\n\u001b[32m    746\u001b[39m         embedding, device=device, use_auth_token=use_auth_token\n\u001b[32m    747\u001b[39m     )\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embedding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mspeechbrain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSpeechBrainPretrainedSpeakerEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_auth_token\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embedding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnvidia\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n\u001b[32m    755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m NeMoPretrainedSpeakerEmbedding(embedding, device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:256\u001b[39m, in \u001b[36mSpeechBrainPretrainedSpeakerEmbedding.__init__\u001b[39m\u001b[34m(self, embedding, device, use_auth_token)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28mself\u001b[39m.device = device \u001b[38;5;129;01mor\u001b[39;00m torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    254\u001b[39m \u001b[38;5;28mself\u001b[39m.use_auth_token = use_auth_token\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[38;5;28mself\u001b[39m.classifier_ = \u001b[43mSpeechBrain_EncoderClassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_hparams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43msavedir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCACHE_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/speechbrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdevice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\speechbrain\\inference\\interfaces.py:477\u001b[39m, in \u001b[36mPretrained.from_hparams\u001b[39m\u001b[34m(cls, source, hparams_file, pymodule_file, overrides, savedir, use_auth_token, revision, download_only, huggingface_cache_dir, overrides_must_match, local_strategy, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_hparams\u001b[39m(\n\u001b[32m    403\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    415\u001b[39m     **kwargs,\n\u001b[32m    416\u001b[39m ):\n\u001b[32m    417\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fetch and load based from outside source based on HyperPyYAML file\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m    419\u001b[39m \u001b[33;03m    The source can be a location on the filesystem or online/huggingface\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    475\u001b[39m \u001b[33;03m    Instance of cls\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     hparams_local_path = \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43msavedir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msavedir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhuggingface_cache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhuggingface_cache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    489\u001b[39m         pymodule_local_path = fetch(\n\u001b[32m    490\u001b[39m             filename=pymodule_file,\n\u001b[32m    491\u001b[39m             source=source,\n\u001b[32m   (...)\u001b[39m\u001b[32m    498\u001b[39m             local_strategy=local_strategy,\n\u001b[32m    499\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:398\u001b[39m, in \u001b[36mfetch\u001b[39m\u001b[34m(filename, source, savedir, overwrite, allow_updates, allow_network, save_filename, use_auth_token, revision, huggingface_cache_dir, local_strategy)\u001b[39m\n\u001b[32m    395\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile not found on HF hub\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlink_with_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetched_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:162\u001b[39m, in \u001b[36mlink_with_strategy\u001b[39m\u001b[34m(src, dst, local_strategy)\u001b[39m\n\u001b[32m    157\u001b[39m     logger.debug(\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFetch: Local file found, creating symlink \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m -> \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, src, dst\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    161\u001b[39m     dst.unlink(missing_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# remove link or delete file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mdst\u001b[49m\u001b[43m.\u001b[49m\u001b[43msymlink_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_strategy \u001b[38;5;129;01min\u001b[39;00m (LocalStrategy.COPY, LocalStrategy.COPY_SKIP_CACHE):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:1386\u001b[39m, in \u001b[36mPath.symlink_to\u001b[39m\u001b[34m(self, target, target_is_directory)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(os, \u001b[33m\"\u001b[39m\u001b[33msymlink\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1385\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mos.symlink() not available on this system\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOSError\u001b[39m: [WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\sainithin\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--spkrec-ecapa-voxceleb\\\\snapshots\\\\0f99f2d0ebe89ac095bcc5903c4dd8f72b367286\\\\hyperparams.yaml' -> 'C:\\\\Users\\\\sainithin\\\\.cache\\\\torch\\\\pyannote\\\\speechbrain\\\\hyperparams.yaml'"
     ]
    }
   ],
   "source": [
    "# instantiate the pipeline\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "HF_KEY = os.getenv(\"HF_KEY\")\n",
    "print(HF_KEY)\n",
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization\",\n",
    "  use_auth_token=HF_KEY)\n",
    "\n",
    "# run the pipeline on an audio file\n",
    "with open(\"Transcription/Case 07.m4a\", \"rb\") as f:\n",
    "  diarization = pipeline(f)\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"audio.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "706e7186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\sai\\yj_tasks\\speaker_diarization\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    }
   ],
   "source": [
    "# instantiate the pipeline\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "HF_KEY = os.getenv(\"HF_KEY\")\n",
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=HF_KEY)\n",
    "\n",
    "# run the pipeline on an audio file\n",
    "with open(\"Transcription/Case 07_converted.wav\", \"rb\") as f:\n",
    "    # diarization = pipeline(f)#, num_speakers=2)\n",
    "    # diarization = pipeline(f, num_speakers=3)\n",
    "    diarization = pipeline(f, min_speakers=2, max_speakers=5)\n",
    "\n",
    "\n",
    "# dump the diarization output to disk using rttm format\n",
    "with open(\"audio.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n",
    "\n",
    "with open(\"audio.lab\", \"w\") as lab:\n",
    "    diarization.write_lab(lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9bd5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Annotation in module pyannote.core.annotation object:\n",
      "\n",
      "class Annotation(builtins.object)\n",
      " |  Annotation(uri: Optional[str] = None, modality: Optional[str] = None)\n",
      " |\n",
      " |  Annotation\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  uri : string, optional\n",
      " |      name of annotated resource (e.g. audio or video file)\n",
      " |  modality : string, optional\n",
      " |      name of annotated modality\n",
      " |\n",
      " |  Returns\n",
      " |  -------\n",
      " |  annotation : Annotation\n",
      " |      New annotation\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __bool__(self)\n",
      " |      Emptiness\n",
      " |\n",
      " |      >>> if annotation:\n",
      " |      ...    # annotation is not empty\n",
      " |      ... else:\n",
      " |      ...    # annotation is empty\n",
      " |\n",
      " |  __contains__(self, included: Union[pyannote.core.segment.Segment, pyannote.core.timeline.Timeline])\n",
      " |      Inclusion\n",
      " |\n",
      " |      Check whether every segment of `included` does exist in annotation.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      included : Segment or Timeline\n",
      " |          Segment or timeline being checked for inclusion\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      contains : bool\n",
      " |          True if every segment in `included` exists in timeline,\n",
      " |          False otherwise\n",
      " |\n",
      " |  __delitem__(self, key: Union[ForwardRef('Segment'), Tuple[ForwardRef('Segment'), Union[str, int]]])\n",
      " |      Delete one track\n",
      " |\n",
      " |      >>> del annotation[segment, track]\n",
      " |\n",
      " |      Delete all tracks of a segment\n",
      " |\n",
      " |      >>> del annotation[segment]\n",
      " |\n",
      " |  __eq__(self, other: 'Annotation')\n",
      " |      Equality\n",
      " |\n",
      " |      >>> annotation == other\n",
      " |\n",
      " |      Two annotations are equal if and only if their tracks and associated\n",
      " |      labels are equal.\n",
      " |\n",
      " |  __getitem__(self, key: Union[ForwardRef('Segment'), Tuple[ForwardRef('Segment'), Union[str, int]]]) -> Hashable\n",
      " |      Get track label\n",
      " |\n",
      " |      >>> label = annotation[segment, track]\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      ``annotation[segment]`` is equivalent to ``annotation[segment, '_']``\n",
      " |\n",
      " |  __init__(self, uri: Optional[str] = None, modality: Optional[str] = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __len__(self)\n",
      " |      Number of segments\n",
      " |\n",
      " |      >>> len(annotation)  # annotation contains three segments\n",
      " |      3\n",
      " |\n",
      " |  __mul__(self, other: 'Annotation') -> numpy.ndarray\n",
      " |      Cooccurrence (or confusion) matrix\n",
      " |\n",
      " |      >>> matrix = annotation * other\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Annotation\n",
      " |          Second annotation\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      cooccurrence : (n_self, n_other) np.ndarray\n",
      " |          Cooccurrence matrix where `n_self` (resp. `n_other`) is the number\n",
      " |          of labels in `self` (resp. `other`).\n",
      " |\n",
      " |  __ne__(self, other: 'Annotation')\n",
      " |      Inequality\n",
      " |\n",
      " |  __nonzero__(self)\n",
      " |\n",
      " |  __setitem__(self, key: Union[ForwardRef('Segment'), Tuple[ForwardRef('Segment'), Union[str, int]]], label: Hashable)\n",
      " |      Add new or update existing track\n",
      " |\n",
      " |      >>> annotation[segment, track] = label\n",
      " |\n",
      " |      If (segment, track) does not exist, it is added.\n",
      " |      If (segment, track) already exists, it is updated.\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      ``annotation[segment] = label`` is equivalent to ``annotation[segment, '_'] = label``\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      If `segment` is empty, it does nothing.\n",
      " |\n",
      " |  __str__(self)\n",
      " |      Human-friendly representation\n",
      " |\n",
      " |  argmax(self, support: Union[ForwardRef('Segment'), ForwardRef('Timeline'), NoneType] = None) -> Optional[Hashable]\n",
      " |      Get label with longest duration\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      support : Segment or Timeline, optional\n",
      " |          Find label with longest duration within provided support.\n",
      " |          Defaults to whole extent.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      label : any existing label or None\n",
      " |          Label with longest intersection\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> annotation = Annotation(modality='speaker')\n",
      " |      >>> annotation[Segment(0, 10), 'speaker1'] = 'Alice'\n",
      " |      >>> annotation[Segment(8, 20), 'speaker1'] = 'Bob'\n",
      " |      >>> print \"%s is such a talker!\" % annotation.argmax()\n",
      " |      Bob is such a talker!\n",
      " |      >>> segment = Segment(22, 23)\n",
      " |      >>> if not annotation.argmax(support):\n",
      " |      ...    print \"No label intersecting %s\" % segment\n",
      " |      No label intersection [22 --> 23]\n",
      " |\n",
      " |  chart(self, percent: bool = False) -> List[Tuple[Hashable, float]]\n",
      " |      Get labels chart (from longest to shortest duration)\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percent : bool, optional\n",
      " |          Return list of (label, percentage) tuples.\n",
      " |          Defaults to returning list of (label, duration) tuples.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      chart : list\n",
      " |          List of (label, duration), sorted by duration in decreasing order.\n",
      " |\n",
      " |  co_iter(self, other: 'Annotation') -> Iterator[Tuple[Tuple[pyannote.core.segment.Segment, Union[str, int]], Tuple[pyannote.core.segment.Segment, Union[str, int]]]]\n",
      " |      Iterate over pairs of intersecting tracks\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Annotation\n",
      " |          Second annotation\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterable : (Segment, object), (Segment, object) iterable\n",
      " |          Yields pairs of intersecting tracks, in chronological (then\n",
      " |          alphabetical) order.\n",
      " |\n",
      " |      See also\n",
      " |      --------\n",
      " |      :func:`~pyannote.core.Timeline.co_iter`\n",
      " |\n",
      " |  copy(self) -> 'Annotation'\n",
      " |      Get a copy of the annotation\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      annotation : Annotation\n",
      " |          Copy of the annotation\n",
      " |\n",
      " |  crop(self, support: Union[ForwardRef('Segment'), ForwardRef('Timeline')], mode: Literal['intersection', 'loose', 'strict'] = 'intersection') -> 'Annotation'\n",
      " |      Crop annotation to new support\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      support : Segment or Timeline\n",
      " |          If `support` is a `Timeline`, its support is used.\n",
      " |      mode : {'strict', 'loose', 'intersection'}, optional\n",
      " |          Controls how segments that are not fully included in `support` are\n",
      " |          handled. 'strict' mode only keeps fully included segments. 'loose'\n",
      " |          mode keeps any intersecting segment. 'intersection' mode keeps any\n",
      " |          intersecting segment but replace them by their actual intersection.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      cropped : Annotation\n",
      " |          Cropped annotation\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      In 'intersection' mode, the best is done to keep the track names\n",
      " |      unchanged. However, in some cases where two original segments are\n",
      " |      cropped into the same resulting segments, conflicting track names are\n",
      " |      modified to make sure no track is lost.\n",
      " |\n",
      " |  discretize(self, support: Optional[pyannote.core.segment.Segment] = None, resolution: Union[float, pyannote.core.segment.SlidingWindow] = 0.01, labels: Optional[List[Hashable]] = None, duration: Optional[float] = None)\n",
      " |      Discretize\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      support : Segment, optional\n",
      " |          Part of annotation to discretize.\n",
      " |          Defaults to annotation full extent.\n",
      " |      resolution : float or SlidingWindow, optional\n",
      " |          Defaults to 10ms frames.\n",
      " |      labels : list of labels, optional\n",
      " |          Defaults to self.labels()\n",
      " |      duration : float, optional\n",
      " |          Overrides support duration and ensures that the number of\n",
      " |          returned frames is fixed (which might otherwise not be the case\n",
      " |          because of rounding errors).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      discretized : SlidingWindowFeature\n",
      " |          (num_frames, num_labels)-shaped binary features.\n",
      " |\n",
      " |  empty(self) -> 'Annotation'\n",
      " |      Return an empty copy\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      empty : Annotation\n",
      " |          Empty annotation using the same 'uri' and 'modality' attributes.\n",
      " |\n",
      " |  extrude(self, removed: Union[ForwardRef('Segment'), ForwardRef('Timeline')], mode: Literal['intersection', 'loose', 'strict'] = 'intersection') -> 'Annotation'\n",
      " |      Remove segments that overlap `removed` support.\n",
      " |\n",
      " |      A simple illustration:\n",
      " |\n",
      " |          annotation\n",
      " |          A |------|    |------|\n",
      " |          B                  |----------|\n",
      " |          C |--------------|              |------|\n",
      " |\n",
      " |          removed `Timeline`\n",
      " |            |-------|  |-----------|\n",
      " |\n",
      " |          extruded Annotation with mode=\"intersection\"\n",
      " |          B                        |---|\n",
      " |          C         |--|                  |------|\n",
      " |\n",
      " |          extruded Annotation with mode=\"loose\"\n",
      " |          C                               |------|\n",
      " |\n",
      " |          extruded Annotation with mode=\"strict\"\n",
      " |          A |------|\n",
      " |          B                  |----------|\n",
      " |          C |--------------|              |------|\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      removed : Segment or Timeline\n",
      " |          If `support` is a `Timeline`, its support is used.\n",
      " |      mode : {'strict', 'loose', 'intersection'}, optional\n",
      " |          Controls how segments that are not fully included in `removed` are\n",
      " |          handled. 'strict' mode only removes fully included segments. 'loose'\n",
      " |          mode removes any intersecting segment. 'intersection' mode removes\n",
      " |          the overlapping part of any intersecting segment.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      extruded : Annotation\n",
      " |          Extruded annotation\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      In 'intersection' mode, the best is done to keep the track names\n",
      " |      unchanged. However, in some cases where two original segments are\n",
      " |      cropped into the same resulting segments, conflicting track names are\n",
      " |      modified to make sure no track is lost.\n",
      " |\n",
      " |  get_labels(self, segment: pyannote.core.segment.Segment, unique: bool = True) -> Union[Set[Hashable], List[Hashable]]\n",
      " |      Query labels by segment\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      segment : Segment\n",
      " |          Query\n",
      " |      unique : bool, optional\n",
      " |          When False, return the list of (possibly repeated) labels.\n",
      " |          Defaults to returning the set of labels.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : set or list\n",
      " |          Set (resp. list) of labels for `segment` if it exists, empty set (resp. list) otherwise\n",
      " |          if unique (resp. if not unique).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> annotation = Annotation()\n",
      " |      >>> segment = Segment(0, 2)\n",
      " |      >>> annotation[segment, 'speaker1'] = 'Bernard'\n",
      " |      >>> annotation[segment, 'speaker2'] = 'John'\n",
      " |      >>> print sorted(annotation.get_labels(segment))\n",
      " |      set(['Bernard', 'John'])\n",
      " |      >>> print annotation.get_labels(Segment(1, 2))\n",
      " |      set([])\n",
      " |\n",
      " |  get_overlap(self, labels: Optional[Iterable[Hashable]] = None) -> 'Timeline'\n",
      " |      Get overlapping parts of the annotation.\n",
      " |\n",
      " |      A simple illustration:\n",
      " |\n",
      " |          annotation\n",
      " |          A |------|    |------|      |----|\n",
      " |          B  |--|    |-----|      |----------|\n",
      " |          C |--------------|      |------|\n",
      " |\n",
      " |          annotation.get_overlap()\n",
      " |            |------| |-----|      |--------|\n",
      " |\n",
      " |          annotation.get_overlap(for_labels=[\"A\", \"B\"])\n",
      " |             |--|       |--|          |----|\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : optional list of labels\n",
      " |          Labels for which to consider the overlap\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      overlap : `pyannote.core.Timeline`\n",
      " |         Timeline of the overlaps.\n",
      " |\n",
      " |  get_timeline(self, copy: bool = True) -> pyannote.core.timeline.Timeline\n",
      " |      Get timeline made of all annotated segments\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, optional\n",
      " |          Defaults (True) to returning a copy of the internal timeline.\n",
      " |          Set to False to return the actual internal timeline (faster).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      timeline : Timeline\n",
      " |          Timeline made of all annotated segments.\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      In case copy is set to False, be careful **not** to modify the returned\n",
      " |      timeline, as it may lead to weird subsequent behavior of the annotation\n",
      " |      instance.\n",
      " |\n",
      " |  get_tracks(self, segment: pyannote.core.segment.Segment) -> Set[Union[str, int]]\n",
      " |      Query tracks by segment\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      segment : Segment\n",
      " |          Query\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tracks : set\n",
      " |          Set of tracks\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      This will return an empty set if segment does not exist.\n",
      " |\n",
      " |  has_track(self, segment: pyannote.core.segment.Segment, track: Union[str, int]) -> bool\n",
      " |      Check whether a given track exists\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      segment : Segment\n",
      " |          Query segment\n",
      " |      track :\n",
      " |          Query track\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      exists : bool\n",
      " |          True if track exists for segment\n",
      " |\n",
      " |  itersegments(self)\n",
      " |      Iterate over segments (in chronological order)\n",
      " |\n",
      " |      >>> for segment in annotation.itersegments():\n",
      " |      ...     # do something with the segment\n",
      " |\n",
      " |      See also\n",
      " |      --------\n",
      " |      :class:`pyannote.core.Segment` describes how segments are sorted.\n",
      " |\n",
      " |  itertracks(self, yield_label: bool = False) -> Iterator[Union[Tuple[pyannote.core.segment.Segment, Union[str, int]], Tuple[pyannote.core.segment.Segment, Union[str, int], Hashable]]]\n",
      " |      Iterate over tracks (in chronological order)\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      yield_label : bool, optional\n",
      " |          When True, yield (segment, track, label) tuples, such that\n",
      " |          annotation[segment, track] == label. Defaults to yielding\n",
      " |          (segment, track) tuple.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |\n",
      " |      >>> for segment, track in annotation.itertracks():\n",
      " |      ...     # do something with the track\n",
      " |\n",
      " |      >>> for segment, track, label in annotation.itertracks(yield_label=True):\n",
      " |      ...     # do something with the track and its label\n",
      " |\n",
      " |  label_duration(self, label: Hashable) -> float\n",
      " |      Label duration\n",
      " |\n",
      " |      Equivalent to ``Annotation.label_timeline(label).duration()``\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Query\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      duration : float\n",
      " |          Duration, in seconds.\n",
      " |\n",
      " |      See also\n",
      " |      --------\n",
      " |      :func:`~pyannote.core.Annotation.label_timeline`\n",
      " |      :func:`~pyannote.core.Timeline.duration`\n",
      " |\n",
      " |  label_support(self, label: Hashable) -> pyannote.core.timeline.Timeline\n",
      " |      Label support\n",
      " |\n",
      " |      Equivalent to ``Annotation.label_timeline(label).support()``\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Query\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      support : Timeline\n",
      " |          Label support\n",
      " |\n",
      " |      See also\n",
      " |      --------\n",
      " |      :func:`~pyannote.core.Annotation.label_timeline`\n",
      " |      :func:`~pyannote.core.Timeline.support`\n",
      " |\n",
      " |  label_timeline(self, label: Hashable, copy: bool = True) -> pyannote.core.timeline.Timeline\n",
      " |      Query segments by label\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          Query\n",
      " |      copy : bool, optional\n",
      " |          Defaults (True) to returning a copy of the internal timeline.\n",
      " |          Set to False to return the actual internal timeline (faster).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      timeline : Timeline\n",
      " |          Timeline made of all segments for which at least one track is\n",
      " |          annotated as label\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      If label does not exist, this will return an empty timeline.\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      In case copy is set to False, be careful **not** to modify the returned\n",
      " |      timeline, as it may lead to weird subsequent behavior of the annotation\n",
      " |      instance.\n",
      " |\n",
      " |  labels(self) -> List[Hashable]\n",
      " |      Get sorted list of labels\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : list\n",
      " |          Sorted list of labels\n",
      " |\n",
      " |  new_track(self, segment: pyannote.core.segment.Segment, candidate: Union[str, int, NoneType] = None, prefix: Optional[str] = None) -> Union[str, int]\n",
      " |      Generate a new track name for given segment\n",
      " |\n",
      " |      Ensures that the returned track name does not already\n",
      " |      exist for the given segment.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      segment : Segment\n",
      " |          Segment for which a new track name is generated.\n",
      " |      candidate : any valid track name, optional\n",
      " |          When provided, try this candidate name first.\n",
      " |      prefix : str, optional\n",
      " |          Track name prefix. Defaults to the empty string ''.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      name : str\n",
      " |          New track name\n",
      " |\n",
      " |  relabel_tracks(self, generator: Union[Literal['int', 'string'], Iterator[Hashable]] = 'string') -> 'Annotation'\n",
      " |      Relabel tracks\n",
      " |\n",
      " |      Create a new annotation where each track has a unique label.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      generator : 'string', 'int' or iterable, optional\n",
      " |          If 'string' (default) relabel tracks to 'A', 'B', 'C', ... If 'int'\n",
      " |          relabel to 0, 1, 2, ... If iterable, use it to generate labels.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Annotation\n",
      " |          New annotation with relabeled tracks.\n",
      " |\n",
      " |  rename_labels(self, mapping: Optional[Dict] = None, generator: Union[Literal['int', 'string'], Iterator[Hashable]] = 'string', copy: bool = True) -> 'Annotation'\n",
      " |      Rename labels\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapping : dict, optional\n",
      " |          {old_name: new_name} mapping dictionary.\n",
      " |      generator : 'string', 'int' or iterable, optional\n",
      " |          If 'string' (default) rename label to 'A', 'B', 'C', ... If 'int',\n",
      " |          rename to 0, 1, 2, etc. If iterable, use it to generate labels.\n",
      " |      copy : bool, optional\n",
      " |          Set to True to return a copy of the annotation. Set to False to\n",
      " |          update the annotation in-place. Defaults to True.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Annotation\n",
      " |          Annotation where labels have been renamed\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      Unmapped labels are kept unchanged.\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      Parameter `generator` has no effect when `mapping` is provided.\n",
      " |\n",
      " |  rename_tracks(self, generator: Union[Literal['int', 'string'], Iterator[Hashable]] = 'string') -> 'Annotation'\n",
      " |      Rename all tracks\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      generator : 'string', 'int', or iterable, optional\n",
      " |          If 'string' (default) rename tracks to 'A', 'B', 'C', etc.\n",
      " |          If 'int', rename tracks to 0, 1, 2, etc.\n",
      " |          If iterable, use it to generate track names.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Annotation\n",
      " |          Copy of the original annotation where tracks are renamed.\n",
      " |\n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> annotation = Annotation()\n",
      " |      >>> annotation[Segment(0, 1), 'a'] = 'a'\n",
      " |      >>> annotation[Segment(0, 1), 'b'] = 'b'\n",
      " |      >>> annotation[Segment(1, 2), 'a'] = 'a'\n",
      " |      >>> annotation[Segment(1, 3), 'c'] = 'c'\n",
      " |      >>> print(annotation)\n",
      " |      [ 00:00:00.000 -->  00:00:01.000] a a\n",
      " |      [ 00:00:00.000 -->  00:00:01.000] b b\n",
      " |      [ 00:00:01.000 -->  00:00:02.000] a a\n",
      " |      [ 00:00:01.000 -->  00:00:03.000] c c\n",
      " |      >>> print(annotation.rename_tracks(generator='int'))\n",
      " |      [ 00:00:00.000 -->  00:00:01.000] 0 a\n",
      " |      [ 00:00:00.000 -->  00:00:01.000] 1 b\n",
      " |      [ 00:00:01.000 -->  00:00:02.000] 2 a\n",
      " |      [ 00:00:01.000 -->  00:00:03.000] 3 c\n",
      " |\n",
      " |  subset(self, labels: Iterable[Hashable], invert: bool = False) -> 'Annotation'\n",
      " |      Filter annotation by labels\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : iterable\n",
      " |          List of filtered labels\n",
      " |      invert : bool, optional\n",
      " |          If invert is True, extract all but requested labels\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      filtered : Annotation\n",
      " |          Filtered annotation\n",
      " |\n",
      " |  support(self, collar: float = 0.0) -> 'Annotation'\n",
      " |      Annotation support\n",
      " |\n",
      " |      The support of an annotation is an annotation where contiguous tracks\n",
      " |      with same label are merged into one unique covering track.\n",
      " |\n",
      " |      A picture is worth a thousand words::\n",
      " |\n",
      " |          collar\n",
      " |          |---|\n",
      " |\n",
      " |          annotation\n",
      " |          |--A--| |--A--|     |-B-|\n",
      " |            |-B-|    |--C--|     |----B-----|\n",
      " |\n",
      " |          annotation.support(collar)\n",
      " |          |------A------|     |------B------|\n",
      " |            |-B-|    |--C--|\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      collar : float, optional\n",
      " |          Merge tracks with same label and separated by less than `collar`\n",
      " |          seconds. This is why 'A' tracks are merged in above figure.\n",
      " |          Defaults to 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      support : Annotation\n",
      " |          Annotation support\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      Track names are lost in the process.\n",
      " |\n",
      " |  to_lab(self) -> str\n",
      " |      Serialize annotation as a string using LAB format\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      serialized: str\n",
      " |          LAB string\n",
      " |\n",
      " |  to_rttm(self) -> str\n",
      " |      Serialize annotation as a string using RTTM format\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      serialized: str\n",
      " |          RTTM string\n",
      " |\n",
      " |  update(self, annotation: 'Annotation', copy: bool = False) -> 'Annotation'\n",
      " |      Add every track of an existing annotation (in place)\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      annotation : Annotation\n",
      " |          Annotation whose tracks are being added\n",
      " |      copy : bool, optional\n",
      " |          Return a copy of the annotation. Defaults to updating the\n",
      " |          annotation in-place.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : Annotation\n",
      " |          Updated annotation\n",
      " |\n",
      " |      Note\n",
      " |      ----\n",
      " |      Existing tracks are updated with the new label.\n",
      " |\n",
      " |  write_lab(self, file: <class 'TextIO'>)\n",
      " |      Dump annotation to file using LAB format\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      file : file object\n",
      " |\n",
      " |      Usage\n",
      " |      -----\n",
      " |      >>> with open('file.lab', 'w') as file:\n",
      " |      ...     annotation.write_lab(file)\n",
      " |\n",
      " |  write_rttm(self, file: <class 'TextIO'>)\n",
      " |      Dump annotation to file using RTTM format\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      file : file object\n",
      " |\n",
      " |      Usage\n",
      " |      -----\n",
      " |      >>> with open('file.rttm', 'w') as file:\n",
      " |      ...     annotation.write_rttm(file)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  from_df(df: 'pd.DataFrame', uri: Optional[str] = None, modality: Optional[str] = None) -> 'Annotation'\n",
      " |\n",
      " |  from_records(records: Iterator[Tuple[pyannote.core.segment.Segment, Union[str, int], Hashable]], uri: Optional[str] = None, modality: Optional[str] = None) -> 'Annotation'\n",
      " |      Annotation\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      records : iterator of tuples\n",
      " |          (segment, track, label) tuples\n",
      " |      uri : string, optional\n",
      " |          name of annotated resource (e.g. audio or video file)\n",
      " |      modality : string, optional\n",
      " |          name of annotated modality\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      annotation : Annotation\n",
      " |          New annotation\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  uri\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9d1f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing FFmpeg command: ffmpeg -i Transcription/Case 07.m4a -ar 16000 -ac 1 Transcription/Case 07_converted.wav\n",
      "ERROR: FFmpeg not found. Please ensure FFmpeg is installed and added to your system's PATH.\n",
      "Failed to convert 'Transcription/Case 07.m4a'. Check errors above.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def convert_audio_with_ffmpeg(input_path, output_path, sample_rate=16000, channels=1):\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        input_path,\n",
    "        \"-ar\", str(sample_rate),\n",
    "        \"-ac\", str(channels),\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    print(f\"Executing FFmpeg command: {' '.join(command)}\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "\n",
    "        print(\"FFmpeg conversion successful!\")\n",
    "        print(\"STDOUT:\\n\", result.stdout)\n",
    "        print(\"STDERR:\\n\", result.stderr)\n",
    "        return True\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: FFmpeg not found. Please ensure FFmpeg is installed and added to your system's PATH.\")\n",
    "        return False\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"ERROR: FFmpeg conversion failed with exit code {e.returncode}\")\n",
    "        print(\"STDOUT:\\n\", e.stdout)\n",
    "        print(\"STDERR:\\n\", e.stderr)\n",
    "        print(f\"Command used: {' '.join(e.cmd)}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during FFmpeg conversion: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_m4a_path = \"Transcription/Case 07.m4a\"\n",
    "    output_wav_path = \"Transcription/Case 07_converted.wav\"\n",
    "\n",
    "    if not os.path.exists(input_m4a_path):\n",
    "        print(f\"'{input_m4a_path}' not found. Please place an .m4a file there or change path.\")\n",
    "        try:\n",
    "            subprocess.run([\"ffmpeg\", \"-f\", \"lavfi\", \"-i\", \"anullsrc=r=44100:cl=mono,atempo=1.0\", \"-t\", \"5\", input_m4a_path], check=True, capture_output=True)\n",
    "            print(f\"Dummy '{input_m4a_path}' created for testing.\")\n",
    "        except (FileNotFoundError, subprocess.CalledProcessError):\n",
    "            print(\"Could not create dummy file. Ensure FFmpeg is installed.\")\n",
    "            exit()\n",
    "\n",
    "\n",
    "    if convert_audio_with_ffmpeg(input_m4a_path, output_wav_path):\n",
    "        print(f\"Successfully converted '{input_m4a_path}' to '{output_wav_path}'\")\n",
    "    else:\n",
    "        print(f\"Failed to convert '{input_m4a_path}'. Check errors above.\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speaker_diarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
